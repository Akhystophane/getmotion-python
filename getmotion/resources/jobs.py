from __future__ import annotations

import logging
import mimetypes
import time
from pathlib import Path
from typing import TYPE_CHECKING, Any, Optional

from ..exceptions import JobFailedError, WaitTimeout
from .storyboard import StoryboardSession

if TYPE_CHECKING:
    from .._http import HttpClient

logger = logging.getLogger("getmotion")

_FAILED_STATUS = "FAILED"
_TERMINAL_STATUSES = {"COMPLETED", "FAILED", "CANCELLED"}


class Job:
    """
    Represents a GetMotion job.

    Obtain via client.jobs.create() or client.jobs.get().
    """

    def __init__(self, job_id: str, http: "HttpClient", data: dict[str, Any] | None = None):
        self.id = job_id
        self._http = http
        self._data: dict[str, Any] = data or {}

    # ------------------------------------------------------------------
    # Status
    # ------------------------------------------------------------------

    def status(self) -> dict[str, Any]:
        """Return current job status detail from the API."""
        return self._http.get(f"/jobs/{self.id}/status")

    def wait_for(
        self,
        status: str,
        timeout: int = 300,
        poll_interval: int = 3,
    ) -> dict[str, Any]:
        """
        Block until the job reaches *status*, then return the status payload.

        Raises:
            JobFailedError: if the job transitions to FAILED before reaching *status*.
            WaitTimeout: if *timeout* seconds elapse without reaching *status*.

        Example:
            job.wait_for("AWAITING_REVIEW", timeout=600)
        """
        deadline = time.monotonic() + timeout
        logger.debug("waiting for job=%s status=%s (timeout=%ss)", self.id, status, timeout)

        while True:
            data = self.status()
            current = data.get("status", "")

            if current == status:
                logger.debug("job=%s reached status=%s", self.id, status)
                return data

            if current == _FAILED_STATUS:
                error = data.get("error") or {}
                raise JobFailedError(
                    f"Job {self.id!r} failed: {error.get('detail', 'unknown error')}",
                    job_id=self.id,
                    code=error.get("code"),
                    detail=error.get("detail"),
                )

            if time.monotonic() >= deadline:
                raise WaitTimeout(self.id, status, timeout)

            time.sleep(poll_interval)

    # ------------------------------------------------------------------
    # Pipeline steps
    # ------------------------------------------------------------------

    def upload_audio(self, path: str | Path, content_type: str | None = None) -> None:
        """
        Presign and upload an audio file to the job's S3 input folder.

        Supports .mp3, .wav, .m4a and other audio formats.
        """
        import httpx

        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f"Audio file not found: {path}")

        if content_type is None:
            guessed, _ = mimetypes.guess_type(str(path))
            content_type = guessed or "audio/mpeg"

        logger.debug("presigning upload for job=%s file=%s", self.id, path.name)
        presign_data = self._http.post(
            "/presign",
            json={"job_id": self.id, "filename": "audio.mp3", "content_type": content_type},
        )

        # Use the first target (root-level key)
        target = presign_data["targets"][0]
        with open(path, "rb") as f:
            audio_bytes = f.read()

        for target in presign_data["targets"]:
            if target.get("fields"):
                response = httpx.post(
                    target["url"],
                    data=target["fields"],
                    files={"file": (path.name, audio_bytes, content_type)},
                )
            else:
                response = httpx.put(
                    target["url"],
                    content=audio_bytes,
                    headers={"Content-Type": content_type},
                )
            response.raise_for_status()
            logger.debug("audio uploaded job=%s key=%s", self.id, target["key"])

    def start(self, input_s3_key: Optional[str] = None) -> dict[str, Any]:
        """Queue compose_pre — kicks off transcription and asset gathering."""
        params = f"?input_s3_key={input_s3_key}" if input_s3_key else ""
        return self._http.post(f"/jobs/{self.id}/start{params}")

    def get_proposal(self) -> dict[str, Any]:
        """Return the domain mapping proposal generated by compose_pre."""
        data = self._http.get(f"/jobs/{self.id}/review/domain_mapping")
        return data["domain_mapping"]

    def submit_review(
        self,
        decisions: dict[str, Any],
        review_token: Optional[str] = None,
    ) -> dict[str, Any]:
        """
        Save the domain mapping review decisions.

        This is called after the user inspects and edits the proposal.
        It does NOT trigger rendering — call job.init_storyboard() next.
        """
        body: dict[str, Any] = {"decisions_json": decisions}
        if review_token:
            body["review_token"] = review_token
        return self._http.post(f"/jobs/{self.id}/review", json=body)

    # ------------------------------------------------------------------
    # Storyboard
    # ------------------------------------------------------------------

    def init_storyboard(self, style: str = "default", force: bool = False) -> StoryboardSession:
        """
        Initialise (or resume) a storyboard editing session.

        If a session already exists for this job it is returned as-is.
        Pass force=True to discard the existing session and generate a new one.
        """
        logger.debug("init storyboard job=%s style=%s force=%s", self.id, style, force)
        data = self._http.post(
            "/storyboard/init",
            json={"job_id": self.id, "style": style, "force": force},
            timeout=None,  # LLM pipeline runs synchronously, no upper bound
        )
        return StoryboardSession(
            session_id=data["session_id"],
            job_id=data["job_id"],
            storyboard_key=data["storyboard_key"],
            version=data["version"],
            high_level_summary=data["high_level_summary"],
            http=self._http,
        )

    # ------------------------------------------------------------------
    # Render
    # ------------------------------------------------------------------

    def render(self, force: bool = False, keep_bin: bool = False) -> dict[str, Any]:
        """
        Queue the job for rendering on the GPU worker.

        The job must be in READY_FOR_INJECT status (i.e. storyboard must be
        finalized first via session.finalize()).

        Args:
            force: Re-render even if renders already exist.
            keep_bin: Skip DaVinci bin cleanup after render (advanced).
        """
        params: list[str] = []
        if force:
            params.append("force=true")
        if keep_bin:
            params.append("keep_bin=true")
        qs = ("?" + "&".join(params)) if params else ""
        return self._http.post(f"/jobs/{self.id}/render{qs}")

    def get_renders(self, version: Optional[str] = None) -> dict[str, Any]:
        """
        Return renders for this job.

        Args:
            version: Blueprint version to fetch (e.g. "v2").
                     Defaults to the latest available version.
        """
        if version:
            return self._http.get(f"/jobs/{self.id}/renders/versions/{version}")
        versions = self.list_render_versions()
        if not versions:
            return {"renders": []}
        # Versions are returned oldest-first; take the last one
        latest = versions[-1]
        return self._http.get(f"/jobs/{self.id}/renders/versions/{latest['version']}")

    def list_render_versions(self) -> list[dict[str, Any]]:
        """Return all available render versions for this job."""
        data = self._http.get(f"/jobs/{self.id}/renders/versions")
        return data.get("versions", [])

    def __repr__(self) -> str:
        return f"<Job id={self.id!r}>"


class JobsResource:
    """Accessed via client.jobs — entry point for job operations."""

    def __init__(self, http: "HttpClient"):
        self._http = http

    def create(
        self,
        title: Optional[str] = None,
        idempotency_key: Optional[str] = None,
        want_upload_url: bool = False,
    ) -> Job:
        """
        Create a new job.

        Args:
            title: Human-readable name, also used as the job_id (alphanumeric/hyphens).
                   A UUID is generated if omitted.
            idempotency_key: Re-using the same key returns the existing job.
            want_upload_url: Request a presigned upload URL in the response.
        """
        body: dict[str, Any] = {"want_upload_url": want_upload_url}
        if title:
            body["title"] = title
        if idempotency_key:
            body["idempotency_key"] = idempotency_key

        data = self._http.post("/jobs", json=body)
        return Job(job_id=data["job_id"], http=self._http, data=data)

    def get(self, job_id: str) -> Job:
        """Fetch an existing job by id."""
        data = self._http.get(f"/jobs/{job_id}")
        return Job(job_id=data["job_id"], http=self._http, data=data)
